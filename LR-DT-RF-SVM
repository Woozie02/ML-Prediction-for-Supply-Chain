# Load the normal and flood datasets from Excel
normal_file_path = r'D:\ACADEMIC\DEGREE\SEM 6\FYP\normal_product_new.xlsx'
flood_file_path = r'D:\ACADEMIC\DEGREE\SEM 6\FYP\flood_product_new.xlsx'

normal_data = pd.read_excel(normal_file_path)
flood_data = pd.read_excel(flood_file_path)

# Combine the datasets
combined_data = pd.concat([normal_data, flood_data], ignore_index=True)

# One-hot encode the 'Product' column and scale the 'Day' column
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['Day']),
        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Product'])
    ]
)

# Define models
models = {
    'Linear Regression': Ridge(),
    'Decision Tree': DecisionTreeRegressor(random_state=42),
    'Random Forest': RandomForestRegressor(random_state=42),
    'SVM': SVR()
}

# Split the data into training and testing sets
X = combined_data[['Day', 'Product']]
y = combined_data['Units Sold']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Train and evaluate each model
results = {}

for name, model in models.items():
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    
    # Fit the model
    pipeline.fit(X_train, y_train)
    
    # Predict on the test set
    y_pred = pipeline.predict(X_test)
    
    # Evaluate the model
    results[name] = {
        'MAE': mean_absolute_error(y_test, y_pred),
        'MSE': mean_squared_error(y_test, y_pred),
        'RMSE': mean_squared_error(y_test, y_pred, squared=False),
        'R2': r2_score(y_test, y_pred)
    }

# Print results for each model
for model_name, metrics in results.items():
    print(f"{model_name} - MAE: {metrics['MAE']:.2f}, MSE: {metrics['MSE']:.2f}, RMSE: {metrics['RMSE']:.2f}, R2: {metrics['R2']:.2f}")
